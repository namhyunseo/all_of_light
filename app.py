import streamlit as st
import os
import pdfplumber
from gemini_client import GeminiClient
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(page_title="Light RAG Chatbot", layout="wide")

st.title("ğŸ“„ ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡ (Light RAG)")

# Sidebar for configuration
with st.sidebar:
    st.header("ì„¤ì •")
    
    # API Key Input
    # Priority: 1. User Input, 2. OS Env (including .env), 3. Streamlit Secrets
    api_key = st.text_input("Google API Key ì…ë ¥", type="password", help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    if not api_key:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            if "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]


    st.divider()
    
    # File Uploader (Admin Only)
    uploaded_file = None
    
    # Check for admin password
    admin_password = st.text_input("ê´€ë¦¬ì ì•”í˜¸ (íŒŒì¼ ì—…ë¡œë“œìš©)", type="password")
    is_admin = False
    
    # Check env/secrets for password (default to 'admin' if not set for testing, but recommend setting it)
    correct_password = os.getenv("ADMIN_PASSWORD") 
    if not correct_password and "ADMIN_PASSWORD" in st.secrets:
        correct_password = st.secrets["ADMIN_PASSWORD"]
        
    if correct_password and admin_password == correct_password:
        is_admin = True
        st.success("ê´€ë¦¬ì í™•ì¸ë¨")
    
    if is_admin:
        uploaded_file = st.file_uploader("ë¬¸ì„œ ì—…ë¡œë“œ (PDF/TXT)", type=["pdf", "txt", "md"])
    else:
        st.info("íŒŒì¼ ì—…ë¡œë“œëŠ” ê´€ë¦¬ìë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (ê¸°ë³¸ ë¬¸ì„œ ì‚¬ìš©)")

    context_text = ""
    # 1. Try to load default file if no upload
    default_file_path = "ì¡°ëª…ì—ëŒ€í•œëª¨ë“ ê²ƒ.md"
    if not uploaded_file and os.path.exists(default_file_path):
        try:
            with open(default_file_path, "r", encoding="utf-8") as f:
                context_text = f.read()
            if is_admin: # Only show this info to admin to avoid clutter
                st.info(f"ê¸°ë³¸ ë¬¸ì„œ '{default_file_path}'ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ({len(context_text)} ì)")
        except Exception as e:
            st.error(f"ê¸°ë³¸ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # 2. Overwrite with uploaded file if exists
    if uploaded_file:
        if uploaded_file.type == "application/pdf":
            with pdfplumber.open(uploaded_file) as pdf:
                pages = [page.extract_text() for page in pdf.pages]
                context_text = "\n".join(filter(None, pages))
        else: # txt or md
            context_text = uploaded_file.read().decode("utf-8")
        
        st.success(f"ìƒˆë¡œìš´ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ! ({len(context_text)} ì)")
    
    if context_text:
        with st.expander("ë¡œë“œëœ í…ìŠ¤íŠ¸ í™•ì¸"):
            st.text(context_text[:1000] + "...")
    else:
        st.info("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# Chat Logic
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# User Input
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    if not api_key:
        st.error("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    elif not context_text:
        st.error("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        # User message
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Assistant message
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ìƒì„± ì¤‘...")
            
            client = GeminiClient(api_key=api_key)
            # Pass history excluding the latest prompt which is handled by send_message inside client (or handle properly)
            # Correction: client.get_chat_response takes history excluding current prompt usually, or we pass valid history.
            # In my client implementation, I passed the history including current prompt? No, let's check.
            # Client code: history_for_gemini = from chat_history. chat.send_message(user_input).
            # So we pass previous messages.
            
            current_history = st.session_state.messages[:-1] # Exclude the just added user prompt
            response_text = client.get_chat_response(current_history, context_text, prompt)
            
            message_placeholder.markdown(response_text)
            
        st.session_state.messages.append({"role": "assistant", "content": response_text})
